---
title: "Gillnet D108 Individual Assignment + Redo D108/111/115"
output:
  html_notebook:
    theme: united
    toc: yes
editor_options: 
  chunk_output_type: inline
---

# Background

After looking at the IA (below), we decided to subsample fish in closer proportion to harvest and redo the D108 Gillnet TBR stock composition. I also looked in to D111, but found no difference. We ended up using the "redo" for D108 Gillnet as 1) the samples better matched harvest and 2) the results better matched run-timing expectation + CWT data.

Also re-running D115 by SW, because the harvest changed so my original mixture is not representative. Run by SW and stratify by "new" harvest.

# Purpose

Troy Thynes (area coordinator for Region 1) noted that the stock composition for Taku in Gillnet District 108 harvest was much higher than had been in the past (8% vs. <2%). What's up with this? Look at individual assignment probabilities to see if it is a lot of fish that could be Stikine...

# *ONCOR* Individual Assignment

```{r}
source("~/../R/Functions.GCL.R")
library(tidyverse)
```

## Get post-QA genotypes

```{r ONCOR_genotypes}
load_sillys(path = "../Genotypes/strata_postQA/", sillyvec = c("D108Gill_2019", "D111Gill_2019"))
load_objects("../Objects/")
```

## Create *ONCOR* input files

```{r ONCOR_input}
gcl2Genepop.GCL(sillyvec = "D108Gill_2019", path = "../ONCOR/Mixture/D108Gill_2019.gen", loci = GAPSLoci, VialNums = TRUE, usat = TRUE)

# Remove "Pop" designations
# rawdat <- scan(file = "../ONCOR/Mixture/D108Gill_2019.gen", what = '', sep = '\n')
# moddat <- rawdat[-grep(pattern = "Pop", x = rawdat)[-1]]
# write.table(x = moddat, file = "../ONCOR/Mixture/D108Gill_2019.gen", quote = FALSE, row.names = FALSE, col.names = FALSE)
```

## Read *ONCOR* output

Need to match up ASL data with *ONCOR* output. This is a bit of a pain in the ass, because the *ONCOR* output is by SillySource, but ASL has WGC and Sample No. Will need to `attributes` table from KSPORT18.
```{r ONCOR_sport_raw_output}
raw_oncor <- scan(file = "../ONCOR/Output/D108Gill_2019_33RG_IA.txt", what = '', sep = '\n', blank.lines.skip = FALSE)
skip <- grep(pattern = "PROBABILITY OF EACH INDIVIDUAL IN THE MIXTURE BELONGING TO EACH REPORTING GROUP", x = raw_oncor) + 1
(D108Gill_dat <- read_delim(file = "../ONCOR/Output/D108Gill_2019_33RG_IA.txt", delim = "\t", skip = skip, trim_ws = TRUE) %>% 
    dplyr::rename(FishID = X1))
```

Sort by Taku probability.
```{r}
D108Gill_dat %>% 
  arrange(desc(Taku))
```

Only three fish that we are pretty confident came from Taku + maybe one more that is most likely Taku. Lots of fish with relatively small probability of being from Taku pushed the stock composition higher.

# Re-Do D108 Gillnet

Mangers thought the stock composition for D108 was a bit off, and looking at the distribution of sampling, we oversampled SW 26 in order to boost sample size. I'm going to subsample fish and reanalyze a more representative mixture.
```{r}
D108Gill_2019.gcl$attributes %>% 
  as_tibble()
```

## Get ASL

#### Read raw ASL
```{r}
(asl_gillnet <- read_csv(file = "../ASL Data/20190822_Gillnet_D8_11_1_15_Detailed ASL Samples.csv"))
```

#### Manipulate ASL
```{r}
(asl_gillnet <- asl_gillnet %>% 
   filter(District %in% 108 & `Length mm` >= 660) %>% 
   filter(`Stat Week` <= 29) %>% 
   filter(!is.na(`Dna Specimen No`))
)
```

## Join attributes

```{r}
D108Gill_2019.gcl$attributes <- D108Gill_2019.gcl$attributes %>% 
  mutate(WGC_4digit = str_sub(string = DNA_TRAY_CODE, start = 7, end = 10)) %>% 
  mutate(WGC_2digit = str_pad(string = DNA_TRAY_WELL_CODE, width = 2, side = "left", pad = 0)) %>% 
  unite("Dna Specimen No", c(WGC_4digit, WGC_2digit), sep = "") %>% 
  mutate("Dna Specimen No" = as.numeric(`Dna Specimen No`)) %>% 
  left_join(asl_gillnet, by = "Dna Specimen No")
```

```{r}
D108Gill_2019.gcl$attributes %>% 
  count(`Stat Week`)
```

## Subsample

### Read Fish Ticket Data
```{r}
(harvest_gillnet <- read_csv(file = "../Harvest Data/20190822_gillnet_ft - Detailed Fish Tickets.csv") %>% 
   filter(District %in% c(108)) %>% 
   filter(between(`Stat Week`, 25, 29)) %>% 
   filter(`Species Code And Name` == "410 - salmon, chinook") %>% 
   filter(`Gear Code` == "03") %>% 
   filter(`Harvest Code` == 11) %>% 
   filter(Year == 2019)
)
```

Keep reducing to figure out how big our mixture can be...
```{r}
(fish_2_pick <- harvest_gillnet %>% 
   group_by(District, `Stat Week`) %>% 
   summarise(harvest = sum(`Number Of Animals (sum)`)) %>% 
   mutate(p_harvest = harvest / sum(harvest)) %>% 
   mutate(n = round(p_harvest * 58))
)
```

Randomly pick fish per week
```{r}
gillnet_108_torerun <- D108Gill_2019.gcl$attributes %>% 
  select(FK_FISH_ID, `Stat Week`) %>% 
  nest(-`Stat Week`) %>% 
  right_join(fish_2_pick, by = "Stat Week") %>% 
  mutate(Sample = map2(data, n, sample_n)) %>% 
  unnest(Sample) %>% 
  select(-data)
```

Verify subsampled fish
```{r}
gillnet_108_torerun %>% 
  count(`Stat Week`)
```

Subsample fish for a new SILLY
```{r}
D108Gill_2019_rerun_vials = list("D108Gill_2019" = as.character(gillnet_108_torerun %>% pull(FK_FISH_ID)))

PoolCollections.GCL(collections = "D108Gill_2019", loci = GAPSLoci_reordered, IDs = D108Gill_2019_rerun_vials, newname = "D108Gill_2019_rerun")
```

# Recreate BAYES files

Create Mixture
```{r}
CreateMixture.GCL(sillys = "D108Gill_2019_rerun", loci = GAPSLoci_reordered, IDs = NULL, mixname = "D108Gill_2019_rerun", dir = "../BAYES/Mixture", type = "BAYES", PT = FALSE)
save_objects(c("D108Gill_2019_rerun_vials", "gillnet_108_torerun"), "../Objects/")
```

Create Control
```{r}
CreateControlFile.GCL(
  sillyvec = SEAKPops357,
  loci = GAPSLoci_reordered,
  mixname = "D108Gill_2019_rerun",
  basename = "GAPS357pops13loci",
  suffix = "",
  nreps = 40000,
  nchains = 5,
  groupvec = GroupVec33RG_357,
  priorvec = TBR_priors[, "D108Gill_2019"],
  initmat = GAPS357PopsInits,
  dir = "../BAYES/Control",
  seeds = WASSIPSockeyeSeeds,
  thin = c(1, 1, 100),
  mixfortran = mixfortran,
  basefortran = bayesfortran_357,
  switches = "F T F T T T F"
)
```

Create Output directory
```{r}
dir.create("../BAYES/Output/D108Gill_2019_rerun")
```

# Resummarise BAYES Estimates

Estimates
```{r}
# full 33 reporting groups
(D108Gill_2019_rerun_33RG_EstimatesStats <-
   CustomCombineBAYESOutput.GCL(
     groupvec = 1:33,
     groupnames = GroupNames33,
     maindir = "../BAYES/Output",
     mixvec = "D108Gill_2019_rerun",
     prior = "",
     ext = "RGN",
     nchains = 5,
     burn = 0.5,
     alpha = 0.1,
     PosteriorOutput = FALSE
   )
)
```

```{r}
(D108Gill_2019_rerun_5RG_EstimatesStats <-
   CustomCombineBAYESOutput.GCL(
     groupvec = GroupVec33RG_to5RG,
     groupnames = GroupNames5,
     maindir = "../BAYES/Output",
     mixvec = "D108Gill_2019_rerun",
     prior = "",
     ext = "RGN",
     nchains = 5,
     burn = 0.5,
     alpha = 0.1,
     PosteriorOutput = FALSE
   )
)
save_objects("D108Gill_2019_rerun_5RG_EstimatesStats", "../Estimates objects/")
```

Compare to original estimates
```{r}
dget("../Estimates objects/TBR_2019_5RG_EstimatesStats.txt")["D108Gill_2019"]
```

```{r}
(D108Gill_2019_rerun_3RG_EstimatesStats <-
   CustomCombineBAYESOutput.GCL(
     groupvec = GroupVec33RG_to3RG,
     groupnames = GroupNames3,
     maindir = "../BAYES/Output",
     mixvec = "D108Gill_2019_rerun",
     prior = "",
     ext = "RGN",
     nchains = 5,
     burn = 0.5,
     alpha = 0.1,
     PosteriorOutput = FALSE
   )
)
save_objects("D108Gill_2019_rerun_3RG_EstimatesStats", "../Estimates objects/")
```

```{r}
(D108Gill_2019_rerun_2RG_EstimatesStats <-
   CustomCombineBAYESOutput.GCL(
     groupvec = GroupVec33RG_to2RG,
     groupnames = GroupNames2,
     maindir = "../BAYES/Output",
     mixvec = "D108Gill_2019_rerun",
     prior = "",
     ext = "RGN",
     nchains = 5,
     burn = 0.5,
     alpha = 0.1,
     PosteriorOutput = FALSE
   )
)
save_objects("D108Gill_2019_rerun_2RG_EstimatesStats", "../Estimates objects/")
```

5RG for spreadsheet
```{r}
# make in to a tidy tibble (tall)
bind_rows(
  lapply("D108Gill_2019_rerun", function(mix) {  # loop over mixture names
    D108Gill_2019_rerun_5RG_EstimatesStats[[mix]] %>%  # for each matrix
      as_tibble(rownames = "group") %>%  # make tibble with rownames as group
      mutate(mixname = mix) %>%  # make column for mixname
      mutate(n_group = n_distinct(group))  # make column for number of groups
  } )
) %>% 
  gather(estimator, value, -mixname, -group, - n_group) %>%  # gather all estimators
  separate(mixname, c("mix", "year"), sep = "_", remove = FALSE) %>%  # extract mixture and year
  separate(mix, c("district", "gear"), sep = 4) %>%  # extract district and gear
  mutate(district = as.integer(str_sub(district, 2, 4))) %>%   # make district integer
  mutate(estimator = factor(estimator, c("mean", "sd", "5%", "95%", "median", "P=0", "GR"))) %>%  # factor for ordering
  mutate(group = factor(group, GroupNames5)) %>%  # factor for ordering
  filter(n_group == 5) %>%  # want 5RG
  filter(estimator %in% c("mean", "sd", "5%", "95%")) %>%  # only relevant estimators
  filter(mixname == "D108Gill_2019_rerun") %>%  # specify mixture
  spread(group, value) %>%  # wide
  select(GroupNames5) %>%  # toss other varialbes
  write.table('clipboard', sep = '\t', row.names = FALSE, col.names = FALSE)  # copy to clipboard
```

3RG for spreadsheet
```{r}
# make in to a tidy tibble (tall)
bind_rows(
  lapply("D108Gill_2019_rerun", function(mix) {  # loop over mixture names
    D108Gill_2019_rerun_3RG_EstimatesStats[[mix]] %>%  # for each matrix
      as_tibble(rownames = "group") %>%  # make tibble with rownames as group
      mutate(mixname = mix) %>%  # make column for mixname
      mutate(n_group = n_distinct(group))  # make column for number of groups
  } )
) %>% 
  gather(estimator, value, -mixname, -group, - n_group) %>%  # gather all estimators
  separate(mixname, c("mix", "year"), sep = "_", remove = FALSE) %>%  # extract mixture and year
  separate(mix, c("district", "gear"), sep = 4) %>%  # extract district and gear
  mutate(district = as.integer(str_sub(district, 2, 4))) %>%   # make district integer
  mutate(estimator = factor(estimator, c("mean", "sd", "5%", "95%", "median", "P=0", "GR"))) %>%  # factor for ordering
  mutate(group = factor(group, GroupNames3)) %>%  # factor for ordering
  filter(n_group == 3) %>%  # want 5RG
  filter(estimator %in% c("mean", "sd", "5%", "95%")) %>%  # only relevant estimators
  filter(mixname == "D108Gill_2019_rerun") %>%  # specify mixture
  spread(group, value) %>%  # wide
  select(GroupNames3) %>%  # toss other varialbes
  write.table('clipboard', sep = '\t', row.names = FALSE, col.names = FALSE)  # copy to clipboard
```

2RG for spreadsheet
```{r}
# make in to a tidy tibble (tall)
bind_rows(
  lapply("D108Gill_2019_rerun", function(mix) {  # loop over mixture names
    D108Gill_2019_rerun_2RG_EstimatesStats[[mix]] %>%  # for each matrix
      as_tibble(rownames = "group") %>%  # make tibble with rownames as group
      mutate(mixname = mix) %>%  # make column for mixname
      mutate(n_group = n_distinct(group))  # make column for number of groups
  } )
) %>% 
  gather(estimator, value, -mixname, -group, - n_group) %>%  # gather all estimators
  separate(mixname, c("mix", "year"), sep = "_", remove = FALSE) %>%  # extract mixture and year
  separate(mix, c("district", "gear"), sep = 4) %>%  # extract district and gear
  mutate(district = as.integer(str_sub(district, 2, 4))) %>%   # make district integer
  mutate(estimator = factor(estimator, c("mean", "sd", "5%", "95%", "median", "P=0", "GR"))) %>%  # factor for ordering
  mutate(group = factor(group, GroupNames2)) %>%  # factor for ordering
  filter(n_group == 2) %>%  # want 5RG
  filter(estimator %in% c("mean", "sd", "5%", "95%")) %>%  # only relevant estimators
  filter(mixname == "D108Gill_2019_rerun") %>%  # specify mixture
  spread(group, value) %>%  # wide
  select(GroupNames2) %>%  # toss other varialbes
  write.table('clipboard', sep = '\t', row.names = FALSE, col.names = FALSE)  # copy to clipboard
```

# Re-Do D111 Gillnet

Mangers thought the stock composition for D108 was a bit off, and looking at the distribution of sampling, we oversampled SW 26 in order to boost sample size. Since we re-did D108, I'm going to look at D111 and subsample fish and reanalyze a more representative mixture. Looking at our original D111 mixture, we had excess samples from SW 27 to make up for the lack of samples from SW 28
```{r}
D111Gill_2019.gcl$attributes %>% 
  as_tibble()
```

## Get ASL

#### Read raw ASL
```{r}
(asl_gillnet <- read_csv(file = "../ASL Data/20190822_Gillnet_D8_11_1_15_Detailed ASL Samples.csv"))
```

#### Manipulate ASL
```{r}
(asl_gillnet <- asl_gillnet %>% 
   filter(District %in% 111 & `Length mm` >= 660) %>% 
   filter(`Stat Week` <= 29) %>% 
   filter(!is.na(`Dna Specimen No`))
)
```

## Join attributes

```{r}
D111Gill_2019.gcl$attributes <- D111Gill_2019.gcl$attributes %>% 
  mutate(WGC_4digit = str_sub(string = DNA_TRAY_CODE, start = 7, end = 10)) %>% 
  mutate(WGC_2digit = str_pad(string = DNA_TRAY_WELL_CODE, width = 2, side = "left", pad = 0)) %>% 
  unite("Dna Specimen No", c(WGC_4digit, WGC_2digit), sep = "") %>% 
  mutate("Dna Specimen No" = as.numeric(`Dna Specimen No`)) %>% 
  left_join(asl_gillnet, by = "Dna Specimen No")
```

```{r}
D111Gill_2019.gcl$attributes %>% 
  count(`Stat Week`)
```

## Subsample

### Read Fish Ticket Data
```{r}
(harvest_gillnet <- read_csv(file = "../Harvest Data/20190822_gillnet_ft - Detailed Fish Tickets.csv") %>% 
   filter(District %in% c(111)) %>% 
   filter(between(`Stat Week`, 25, 29)) %>% 
   filter(`Species Code And Name` == "410 - salmon, chinook") %>% 
   filter(`Gear Code` == "03") %>% 
   filter(`Harvest Code` == 11) %>% 
   filter(Year == 2019)
)
```

Keep reducing to figure out how big our mixture can be...
```{r}
(fish_2_pick <- harvest_gillnet %>% 
   group_by(District, `Stat Week`) %>% 
   summarise(harvest = sum(`Number Of Animals (sum)`)) %>% 
   mutate(p_harvest = harvest / sum(harvest)) %>% 
   mutate(n = round(p_harvest * 82))
)
```

Randomly pick fish per week
```{r}
gillnet_111_torerun <- D111Gill_2019.gcl$attributes %>% 
  select(FK_FISH_ID, `Stat Week`) %>% 
  nest(-`Stat Week`) %>% 
  right_join(fish_2_pick, by = "Stat Week") %>% 
  mutate(Sample = map2(data, n, sample_n)) %>% 
  unnest(Sample) %>% 
  select(-data)
```

Verify subsampled fish
```{r}
gillnet_111_torerun %>% 
  count(`Stat Week`)
```

Subsample fish for a new SILLY
```{r}
D111Gill_2019_rerun_vials = list("D111Gill_2019" = as.character(gillnet_111_torerun %>% pull(FK_FISH_ID)))

PoolCollections.GCL(collections = "D111Gill_2019", loci = GAPSLoci_reordered, IDs = D111Gill_2019_rerun_vials, newname = "D111Gill_2019_rerun")
```

# Recreate BAYES files

Create Mixture
```{r}
CreateMixture.GCL(sillys = "D111Gill_2019_rerun", loci = GAPSLoci_reordered, IDs = NULL, mixname = "D111Gill_2019_rerun", dir = "../BAYES/Mixture", type = "BAYES", PT = FALSE)
save_objects(c("D111Gill_2019_rerun_vials", "gillnet_111_torerun"), "../Objects/")
```

Create Control
```{r}
CreateControlFile.GCL(
  sillyvec = SEAKPops357,
  loci = GAPSLoci_reordered,
  mixname = "D111Gill_2019_rerun",
  basename = "GAPS357pops13loci",
  suffix = "",
  nreps = 40000,
  nchains = 5,
  groupvec = GroupVec33RG_357,
  priorvec = TBR_priors[, "D111Gill_2019"],
  initmat = GAPS357PopsInits,
  dir = "../BAYES/Control",
  seeds = WASSIPSockeyeSeeds,
  thin = c(1, 1, 100),
  mixfortran = mixfortran,
  basefortran = bayesfortran_357,
  switches = "F T F T T T F"
)
```

Create Output directory
```{r}
dir.create("../BAYES/Output/D111Gill_2019_rerun")
```

# Resummarise BAYES Estimates

Estimates
```{r}
# full 33 reporting groups
(D111Gill_2019_rerun_33RG_EstimatesStats <-
   CustomCombineBAYESOutput.GCL(
     groupvec = 1:33,
     groupnames = GroupNames33,
     maindir = "../BAYES/Output",
     mixvec = "D111Gill_2019_rerun",
     prior = "",
     ext = "RGN",
     nchains = 5,
     burn = 0.5,
     alpha = 0.1,
     PosteriorOutput = FALSE
   )
)
```

```{r}
(D111Gill_2019_rerun_5RG_EstimatesStats <-
   CustomCombineBAYESOutput.GCL(
     groupvec = GroupVec33RG_to5RG,
     groupnames = GroupNames5,
     maindir = "../BAYES/Output",
     mixvec = "D111Gill_2019_rerun",
     prior = "",
     ext = "RGN",
     nchains = 5,
     burn = 0.5,
     alpha = 0.1,
     PosteriorOutput = FALSE
   )
)
save_objects("D111Gill_2019_rerun_5RG_EstimatesStats", "../Estimates objects/")
```

Compare to original estimates
```{r}
dget("../Estimates objects/TBR_2019_5RG_EstimatesStats.txt")["D111Gill_2019"]
```

```{r}
(D111Gill_2019_rerun_3RG_EstimatesStats <-
   CustomCombineBAYESOutput.GCL(
     groupvec = GroupVec33RG_to3RG,
     groupnames = GroupNames3,
     maindir = "../BAYES/Output",
     mixvec = "D111Gill_2019_rerun",
     prior = "",
     ext = "RGN",
     nchains = 5,
     burn = 0.5,
     alpha = 0.1,
     PosteriorOutput = FALSE
   )
)
save_objects("D111Gill_2019_rerun_3RG_EstimatesStats", "../Estimates objects/")
```

```{r}
(D111Gill_2019_rerun_2RG_EstimatesStats <-
   CustomCombineBAYESOutput.GCL(
     groupvec = GroupVec33RG_to2RG,
     groupnames = GroupNames2,
     maindir = "../BAYES/Output",
     mixvec = "D111Gill_2019_rerun",
     prior = "",
     ext = "RGN",
     nchains = 5,
     burn = 0.5,
     alpha = 0.1,
     PosteriorOutput = FALSE
   )
)
save_objects("D111Gill_2019_rerun_2RG_EstimatesStats", "../Estimates objects/")
```

5RG for spreadsheet
```{r}
# make in to a tidy tibble (tall)
bind_rows(
  lapply("D111Gill_2019_rerun", function(mix) {  # loop over mixture names
    D111Gill_2019_rerun_5RG_EstimatesStats[[mix]] %>%  # for each matrix
      as_tibble(rownames = "group") %>%  # make tibble with rownames as group
      mutate(mixname = mix) %>%  # make column for mixname
      mutate(n_group = n_distinct(group))  # make column for number of groups
  } )
) %>% 
  gather(estimator, value, -mixname, -group, - n_group) %>%  # gather all estimators
  separate(mixname, c("mix", "year"), sep = "_", remove = FALSE) %>%  # extract mixture and year
  separate(mix, c("district", "gear"), sep = 4) %>%  # extract district and gear
  mutate(district = as.integer(str_sub(district, 2, 4))) %>%   # make district integer
  mutate(estimator = factor(estimator, c("mean", "sd", "5%", "95%", "median", "P=0", "GR"))) %>%  # factor for ordering
  mutate(group = factor(group, GroupNames5)) %>%  # factor for ordering
  filter(n_group == 5) %>%  # want 5RG
  filter(estimator %in% c("mean", "sd", "5%", "95%")) %>%  # only relevant estimators
  filter(mixname == "D111Gill_2019_rerun") %>%  # specify mixture
  spread(group, value) %>%  # wide
  select(GroupNames5) %>%  # toss other varialbes
  write.table('clipboard', sep = '\t', row.names = FALSE, col.names = FALSE)  # copy to clipboard
```

3RG for spreadsheet
```{r}
# make in to a tidy tibble (tall)
bind_rows(
  lapply("D111Gill_2019_rerun", function(mix) {  # loop over mixture names
    D111Gill_2019_rerun_3RG_EstimatesStats[[mix]] %>%  # for each matrix
      as_tibble(rownames = "group") %>%  # make tibble with rownames as group
      mutate(mixname = mix) %>%  # make column for mixname
      mutate(n_group = n_distinct(group))  # make column for number of groups
  } )
) %>% 
  gather(estimator, value, -mixname, -group, - n_group) %>%  # gather all estimators
  separate(mixname, c("mix", "year"), sep = "_", remove = FALSE) %>%  # extract mixture and year
  separate(mix, c("district", "gear"), sep = 4) %>%  # extract district and gear
  mutate(district = as.integer(str_sub(district, 2, 4))) %>%   # make district integer
  mutate(estimator = factor(estimator, c("mean", "sd", "5%", "95%", "median", "P=0", "GR"))) %>%  # factor for ordering
  mutate(group = factor(group, GroupNames3)) %>%  # factor for ordering
  filter(n_group == 3) %>%  # want 5RG
  filter(estimator %in% c("mean", "sd", "5%", "95%")) %>%  # only relevant estimators
  filter(mixname == "D111Gill_2019_rerun") %>%  # specify mixture
  spread(group, value) %>%  # wide
  select(GroupNames3) %>%  # toss other varialbes
  write.table('clipboard', sep = '\t', row.names = FALSE, col.names = FALSE)  # copy to clipboard
```

2RG for spreadsheet
```{r}
# make in to a tidy tibble (tall)
bind_rows(
  lapply("D111Gill_2019_rerun", function(mix) {  # loop over mixture names
    D111Gill_2019_rerun_2RG_EstimatesStats[[mix]] %>%  # for each matrix
      as_tibble(rownames = "group") %>%  # make tibble with rownames as group
      mutate(mixname = mix) %>%  # make column for mixname
      mutate(n_group = n_distinct(group))  # make column for number of groups
  } )
) %>% 
  gather(estimator, value, -mixname, -group, - n_group) %>%  # gather all estimators
  separate(mixname, c("mix", "year"), sep = "_", remove = FALSE) %>%  # extract mixture and year
  separate(mix, c("district", "gear"), sep = 4) %>%  # extract district and gear
  mutate(district = as.integer(str_sub(district, 2, 4))) %>%   # make district integer
  mutate(estimator = factor(estimator, c("mean", "sd", "5%", "95%", "median", "P=0", "GR"))) %>%  # factor for ordering
  mutate(group = factor(group, GroupNames2)) %>%  # factor for ordering
  filter(n_group == 2) %>%  # want 5RG
  filter(estimator %in% c("mean", "sd", "5%", "95%")) %>%  # only relevant estimators
  filter(mixname == "D111Gill_2019_rerun") %>%  # specify mixture
  spread(group, value) %>%  # wide
  select(GroupNames2) %>%  # toss other varialbes
  write.table('clipboard', sep = '\t', row.names = FALSE, col.names = FALSE)  # copy to clipboard
```

# ASL metadata

The summary spreadsheet has tabs for "Gill_SampleInfo" and "Sport_SampleInfo" that has the ASL data for all TBR fish run since 2004. Need to add the ASL metadata from this year as well.

Need to recreate D108Gill_2019_redo from **BAYES** mixture file...ugh
```{r}
save_sillys("D108Gill_2019_rerun", "../Genotypes/strata_postQA/")
```

## Gillnet

Read in gillnet ASL data for extracted fish and add to spreadsheet, then re-do pivot table.
```{r gill_metadata}
# join extraction asl with fish passing QA, select columns, copy to clipboard
asl_gillnet <- read_csv(file = "../ASL Data/20190822_Gillnet_D8_11_1_15_Detailed ASL Samples.csv") %>% 
  mutate(Subdistrict = `Sub-District`) %>%  # str_sub(District, 5, 6)
  mutate(SizeClass = case_when(`Average Length mm` >= 660 ~ "LARGE",
                               `Average Length mm` < 660 ~ "SMALL")) %>% 
  filter(District %in% c(108, 111)) %>% 
  right_join(
    bind_rows(
      D108Gill_2019_rerun.gcl$attributes %>% 
        mutate(WGC4digit = str_sub(DNA_TRAY_CODE, 7, 10)) %>% 
        mutate(WGC2digit = str_pad(DNA_TRAY_WELL_CODE, 2, "left", "0")) %>% 
        unite("Dna Specimen No", c(WGC4digit, WGC2digit), sep = "") %>% 
        mutate(`Dna Specimen No` = as.integer(`Dna Specimen No`)) %>% 
        select(`Dna Specimen No`),
      D111Gill_2019.gcl$attributes %>% 
        mutate(WGC4digit = str_sub(DNA_TRAY_CODE, 7, 10)) %>% 
        mutate(WGC2digit = str_pad(DNA_TRAY_WELL_CODE, 2, "left", "0")) %>% 
        unite("Dna Specimen No", c(WGC4digit, WGC2digit), sep = "") %>% 
        mutate(`Dna Specimen No` = as.integer(`Dna Specimen No`)) %>% 
        select(`Dna Specimen No`)
    )
    , by = "Dna Specimen No") %>% 
  select(Year, `Sample Date`, `Stat Week`, `Port Code`, District, Subdistrict, `Average Length mm`, SizeClass, `Dna Specimen No`) %>% 
  write.table('clipboard', sep = '\t', row.names = FALSE, col.names = FALSE)
```

# D115 *ONCOR* Individual Assignment

```{r}
source("~/../R/Functions.GCL.R")
library(tidyverse)
```

## Get post-QA genotypes

```{r}
load_sillys(path = "../Genotypes/strata_postQA/", sillyvec = "D115Gill_2019")
load_objects("../Objects/")
```

## Create *ONCOR* input files

```{r}
gcl2Genepop.GCL(sillyvec = "D115Gill_2019", path = "../ONCOR/Mixture/D115Gill_2019.gen", loci = GAPSLoci, VialNums = TRUE, usat = TRUE)

# Remove "Pop" designations
# rawdat <- scan(file = "../ONCOR/Mixture/D108Gill_2019.gen", what = '', sep = '\n')
# moddat <- rawdat[-grep(pattern = "Pop", x = rawdat)[-1]]
# write.table(x = moddat, file = "../ONCOR/Mixture/D108Gill_2019.gen", quote = FALSE, row.names = FALSE, col.names = FALSE)
```

## Read *ONCOR* output

Need to match up ASL data with *ONCOR* output. This is a bit of a pain in the ass, because the *ONCOR* output is by SillySource, but ASL has WGC and Sample No. Will need to `attributes` table from KSPORT18.
```{r}
raw_oncor <- scan(file = "../ONCOR/Output/D115Gill_2019_33RG_IA.txt", what = '', sep = '\n', blank.lines.skip = FALSE)
skip <- grep(pattern = "PROBABILITY OF EACH INDIVIDUAL IN THE MIXTURE BELONGING TO EACH REPORTING GROUP", x = raw_oncor) + 1
(D115Gill_dat <- read_delim(file = "../ONCOR/Output/D115Gill_2019_33RG_IA.txt", delim = "\t", skip = skip, trim_ws = TRUE) %>% 
    dplyr::rename(FishID = X1))
```

Sort by Taku probability.
```{r}
D115Gill_dat %>% 
  arrange(desc(Taku))
```


Sort by Andrew probability.
```{r}
D115Gill_dat %>% 
  arrange(desc(Andrew))
```

```{r}
D115Gill_dat %>% 
  gather(RG, prob, -FishID) %>% 
  filter(RG %in% c("NSEAK", "SSEAK", "Taku", "Andrew", "Stikine")) %>% 
  ggplot(aes(x = prob)) +
  geom_histogram() +
  facet_grid(. ~ RG)
```

```{r}
load_sillys(path = "../Genotypes/strata_postQA/", sillyvec = "D115Gill_2019")
```

```{r}
D115Gill_2019.gcl$attributes %>% 
  mutate(WGC4 = str_sub(DNA_TRAY_CODE, 7, 10)) %>% 
  mutate(WGC2 = str_pad(DNA_TRAY_WELL_CODE, 2, "left", "0")) %>% 
  unite(dna_specimen_no, c("WGC4", "WGC2"), sep = "") %>% 
  mutate("Dna Specimen No" = as.numeric(dna_specimen_no)) %>% 
  left_join(filter(asl_gillnet, District == 115), by = "Dna Specimen No") %>% 
  select(SillySource, `Stat Week`) %>%
  filter(SillySource %in% c("KGILL19D15_192", "KGILL19D15_13", "KGILL19D15_79", "KGILL19D15_10", "KGILL19D15_55", "KGILL19D15_200", "KGILL19D15_119"))
```

```{r}
D115Gill_2019.gcl$attributes %>% 
  mutate(WGC4 = str_sub(DNA_TRAY_CODE, 7, 10)) %>% 
  mutate(WGC2 = str_pad(DNA_TRAY_WELL_CODE, 2, "left", "0")) %>% 
  unite(dna_specimen_no, c("WGC4", "WGC2"), sep = "") %>% 
  mutate("Dna Specimen No" = as.numeric(dna_specimen_no)) %>% 
  left_join(filter(asl_gillnet, District == 115), by = "Dna Specimen No") %>% 
  select(SillySource, `Stat Week`) %>% 
  left_join(D115Gill_dat, by = c("SillySource" = "FishID")) %>% 
  filter(NSEAK > 0.8) %>% 
  count(`Stat Week`)
```

# Re-Do D151 Gillnet

I picked fish for extraction from SW 25-29 at the end of SW34, however, it looks like the harvest numbers were incorrect (late fish tickets). Need to run each week separately and stratify across weeks according to harvest. Not planning to run any more fish.

```{r}
load_sillys(path = "../Genotypes/strata_postQA/", sillyvec = "D115Gill_2019")
load_objects("../Objects/")
```

```{r}
D115Gill_2019.gcl$attributes %>% 
  as_tibble()
```

## Get ASL

#### Read raw ASL
```{r}
(asl_gillnet <- read_csv(file = "../ASL Data/20190822_Gillnet_D8_11_1_15_Detailed ASL Samples.csv"))
```

#### Manipulate ASL
```{r}
(asl_gillnet <- asl_gillnet %>% 
   filter(District %in% 115) %>% 
   filter(`Stat Week` <= 29) %>% 
   filter(!is.na(`Dna Specimen No`))
)
```

## Join attributes

```{r}
D115Gill_2019.gcl$attributes <- D115Gill_2019.gcl$attributes %>% 
  mutate(WGC_4digit = str_sub(string = DNA_TRAY_CODE, start = 7, end = 10)) %>% 
  mutate(WGC_2digit = str_pad(string = DNA_TRAY_WELL_CODE, width = 2, side = "left", pad = 0)) %>% 
  unite("Dna Specimen No", c(WGC_4digit, WGC_2digit), sep = "") %>% 
  mutate("Dna Specimen No" = as.numeric(`Dna Specimen No`)) %>% 
  left_join(asl_gillnet, by = "Dna Specimen No")
```

```{r}
D115Gill_2019.gcl$attributes %>% 
  count(`Stat Week`)
```

## Define Mixture Strata
```{r}
D115Gill_SW25_2019.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "D115Gill_2019", attribute = "Stat Week", matching = 25)), nm = "D115Gill_2019")
PoolCollections.GCL(collections = "D115Gill_2019", loci = GAPSLoci_reordered, IDs = D115Gill_SW25_2019.vials, newname = "D115Gill_SW25_2019")

D115Gill_SW26_2019.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "D115Gill_2019", attribute = "Stat Week", matching = 26)), nm = "D115Gill_2019")
PoolCollections.GCL(collections = "D115Gill_2019", loci = GAPSLoci_reordered, IDs = D115Gill_SW26_2019.vials, newname = "D115Gill_SW26_2019")

D115Gill_SW27_2019.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "D115Gill_2019", attribute = "Stat Week", matching = 27)), nm = "D115Gill_2019")
PoolCollections.GCL(collections = "D115Gill_2019", loci = GAPSLoci_reordered, IDs = D115Gill_SW27_2019.vials, newname = "D115Gill_SW27_2019")

D115Gill_SW28_2019.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "D115Gill_2019", attribute = "Stat Week", matching = 28)), nm = "D115Gill_2019")
PoolCollections.GCL(collections = "D115Gill_2019", loci = GAPSLoci_reordered, IDs = D115Gill_SW28_2019.vials, newname = "D115Gill_SW28_2019")

D115Gill_SW29_2019.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "D115Gill_2019", attribute = "Stat Week", matching = 29)), nm = "D115Gill_2019")
PoolCollections.GCL(collections = "D115Gill_2019", loci = GAPSLoci_reordered, IDs = D115Gill_SW29_2019.vials, newname = "D115Gill_SW29_2019")

D115Gill_mixnames <- paste0("D115Gill_SW", 25:29, "_2019")

sapply(D115Gill_mixnames, function(mix) {get(paste0(mix, ".gcl"))$n})

save_objects("D115Gill_mixnames", "../Objects/")
save_sillys(D115Gill_mixnames, "../Genotypes/strata_postQA/")
```

## Create mixtures

Create gillnet *BAYES* mixture files.
```{r BAYES_mixtures}
sapply(D115Gill_mixnames, function(mix) {
  CreateMixture.GCL(sillys = mix, loci = GAPSLoci_reordered, IDs = NULL, mixname = mix, dir = "../BAYES/Mixture", type = "BAYES", PT = FALSE)
} )
```

## Create priors

New this year, as last year, I will be analyzing **ALL** Chinook mixtures with the full 33 reporting groups, including gillnet. However, since we have never run either of these mixtures before, what to do for a prior? Going with flat.

My plan is to keep the same prior for the gillnet groups and then spread out the "Other" evenly across all other non-gillnet reporting groups.
Now get 2018 esimates for Sport D111 + Gillnet 108 and 111
```{r}
# flat_prior <- Prior.GCL(groupvec = GroupVec33RG_357, groupweights = rep(1/33, 33))
# save_objects("flat_prior", "../Objects/")
```

## Create control files

Now that we have priors, just need to create *BAYES* control files.
```{r BAYES_control}
sapply(D115Gill_mixnames, function(mix) {
  CreateControlFile.GCL(
    sillyvec = SEAKPops357,
    loci = GAPSLoci_reordered,
    mixname = mix,
    basename = "GAPS357pops13loci",
    suffix = "",
    nreps = 40000,
    nchains = 5,
    groupvec = GroupVec33RG_357,
    priorvec = flat_prior,
    initmat = GAPS357PopsInits,
    dir = "../BAYES/Control",
    seeds = WASSIPSockeyeSeeds,
    thin = c(1, 1, 100),
    mixfortran = mixfortran,
    basefortran = bayesfortran_357,
    switches = "F T F T F T F"
  )
})
```

## Create output directories

```{r BAYES_output}
sapply(D115Gill_mixnames, function(mix) {dir.create(paste0("../BAYES/Output/", mix))} )
```
